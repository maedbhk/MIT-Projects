---
title: Ethical Considerations for pHealth
---

**Anyone doing precision medicine must never lose sight of the individual who is relying on experts (e.g., scientists, clinicians) to do no harm in providing them with the best possible healthcare outcomes.**

> Much of the points below came from a [review paper](https://pubmed.ncbi.nlm.nih.gov/33091314/) by MacEachern and Forkert (2020)

1. ML approaches require large amounts of data, therefore data will be collected from many locations and transferred to a central location for storage and processing. essential that the datasets do not contain patient-identifying information. in the future, this could be overcome using distributed machine learning approaches (e.g., travelling ML model) - trains locally on the available data, before moving to the next center with available data [Tuladhar et al. 2020](https://www.sciencedirect.com/science/article/pii/S1532046420300526?via%3Dihub)
2. ML models as "black boxes", especially with increased complexity of the input data. this raises legal and ethical questions as clinicians and other researchers may not fully understand how an ML model came to a particular conclusion about a patient's health. 
3. As physicians can be held legally responsible for their decisions, error in ML models is of course a concern. Who is responsible for an error induced in an ML model? These tools (for the time being) will support and assist physicians in making decisions about patient care, they are not yet designed to operate autonomously. 
4. There are technical limitations to ML models, which is that these models are only as good as the data on which they were trained. However, these training datasets are often inherently noisy and biased. What this means is that models are being created that cannot generalize to more diverse test sets (other regions, diseases, demographics). The easiest way to avoid this problem is to increase the training set and include a diversity of samples, however, this often has logistical (e.g., privacy) challenges. 
5. Financial cost is another major concern with pHealth, which will lead to disparities in access to care based on SES. Also, in-depth workups can lead to unintended consequences such as incidental findings that may lead to further testing, which may be invasive and unnecessary, inducing patient stress in the face of diagnostic uncertainty. 
6. Communicating uncertainty. there is rarely a clear-cut answer in science, our interpretations operate on probability and likelihood. communicating uncertainty to scientists and non-scientists alike is challenging, especially when decisions are being made that will influence a person's healthcare outcomes. Therefore, it is important that future machine learning models can identify the most important clinical features for a specific clinical question so that unnecessary assessments can be avoided, maximizing benefit and minimizing harm to patients. 
7. Bias in datasets is one of the most pressing concerns for pHealth. bias can come about due to patient selection, affecting the accuracy and generalizability of the model. Additionally, the financial and practical aspects of implementing pHealth limits the models primarily to the developed world, excluding those in the developing world from the analyses, and any benefits that are offered. 
8. A yet unanswered question is whether discoveries made by pHealth will have individual impacts on human behavior with respect to disease prevention. For example, if a patient knows that they are at risk for heart disease based on underlying genetic or epigenetic factors, will they change their behavior? Also, it's possible that such discoveries will create "patients-in-waiting" who are not yet sick but have been identified as high risk. 
